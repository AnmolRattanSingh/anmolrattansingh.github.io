<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Concepts &amp; Theory on Gati Aher&#39;s Blog</title>
    <link>http://GatiAher.github.io/categories/concepts-theory/</link>
    <description>Recent content in Concepts &amp; Theory on Gati Aher&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 23 Dec 2021 20:08:21 -0500</lastBuildDate>
    
	<atom:link href="http://GatiAher.github.io/categories/concepts-theory/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Exploring FPGA Deep Learning Accelerators</title>
      <link>http://GatiAher.github.io/projects/exploring-fpga-deep-learning-accelerators/</link>
      <pubDate>Thu, 23 Dec 2021 20:08:21 -0500</pubDate>
      
      <guid>http://GatiAher.github.io/projects/exploring-fpga-deep-learning-accelerators/</guid>
      <description>&lt;p&gt;I wanted to learn about the process of using FPGA hardware accelerators for more power-efficient deep learning inference. Through this project, I learned about the process of creating and building an image for the Zybo ZYNQ FPGA, PYNQ application development, and Vitis AI development tools. I also surveyed the functionality of FINN, an experimental framework from Xilinx Research Labs to explore quantized deep neural network inference on FPGAs.&lt;/p&gt;
&lt;div id=&#34;Container&#34;
  style=&#34;padding-bottom:56.25%; position:relative; display:block; width: 100%&#34;&gt;
  &lt;iframe id=&#34;googlePdfIframe&#34;
  width=&#34;100%&#34; height=&#34;100%&#34;
  src=&#34;https://drive.google.com/file/d/1SVpb3sdzzIIEaEiwaT3kFwRgV2HywIRb/preview&#34;
  frameborder=&#34;0&#34; allowfullscreen=&#34;&#34;
  style=&#34;position:absolute; top:0; left: 0&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Procedural Graph Generation For More Realistic Simulations</title>
      <link>http://GatiAher.github.io/projects/procedural-graph-generation-for-more-realistic-simulations/</link>
      <pubDate>Sat, 18 Dec 2021 23:23:16 -0500</pubDate>
      
      <guid>http://GatiAher.github.io/projects/procedural-graph-generation-for-more-realistic-simulations/</guid>
      <description>&lt;p&gt;Many real world systems can be modeled with graphs. Most stable and complex graphs have &lt;strong&gt;small-world&lt;/strong&gt; (local clustering) and &lt;strong&gt;scale-free&lt;/strong&gt; (hubs) properties. In this project, we (1) identified algorithms that generated small-world and scale-free graphs, (2) studied and implemented generation functions for each type of algorithm, (3) created custom animations of graph generation process, and (4) verified that our graphs exhibited the expected structural properties.&lt;/p&gt;
&lt;p&gt;All generation, animation, and validation code is available in our &lt;a href=&#34;https://github.com/GatiAher/network-generation&#34;&gt;GitHub Repo&lt;/a&gt;.&lt;/p&gt;


&lt;div id=&#34;Container&#34;
 style=&#34;padding-bottom:56.25%; position:relative; display:block; width: 100%&#34;&gt;
 &lt;iframe id=&#34;googleSlideIframe&#34;
  width=&#34;100%&#34; height=&#34;100%&#34;
  src=&#34;https://docs.google.com/presentation/d/e/2PACX-1vRoVNJKtW84R-zlSBe9CBJO1PGcZwgc7_wVDoCUYklCmjqXsDLeqK1ipSAd0XweKgvaql3kSxRcF7YA/embed?start=false&amp;amp;loop=false&amp;amp;delayms=3000&#34;
  frameborder=&#34;0&#34; allowfullscreen=&#34;&#34;
  style=&#34;position:absolute; top:0; left: 0&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Disco-Cats: Arduinos &#43; ML Music</title>
      <link>http://GatiAher.github.io/projects/disco-cats-arduinos&#43;ml-music/</link>
      <pubDate>Tue, 14 Dec 2021 21:21:42 -0400</pubDate>
      
      <guid>http://GatiAher.github.io/projects/disco-cats-arduinos&#43;ml-music/</guid>
      <description>&lt;p&gt;My team spent 6 weeks building an interactive music visualization system that uses Arduinos, motors, an LED matrix, and sound to express musical pieces generated with machine learning!&lt;/p&gt;
&lt;p&gt;I learned how to (1) design an intuitive UI (2) use &lt;a href=&#34;https://magenta.tensorflow.org/multitrack&#34;&gt;Google&amp;rsquo;s Magenta multi-track VAE model&lt;/a&gt; to generate music based on user input (3) transmit the MIDI bitstream over serial (3) extract pitch, instrument, and duration information from the midi bitstream in real time (4) efficiently control an LED matrix and motors.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Details are available on our &lt;a href=&#34;https://olincollege.github.io/pie-2021-03/Disco-Cats/&#34;&gt;&lt;em&gt;Showcase Website!&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Code is on &lt;a href=&#34;https://github.com/GatiAher/disco_cats&#34;&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Demo video is on &lt;a href=&#34;https://youtu.be/nX_OTCaxyTM&#34;&gt;YouTube&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Deep Dive Into Huffman Coding</title>
      <link>http://GatiAher.github.io/projects/deep-dive-into-huffman-coding/</link>
      <pubDate>Mon, 25 Oct 2021 00:46:56 -0500</pubDate>
      
      <guid>http://GatiAher.github.io/projects/deep-dive-into-huffman-coding/</guid>
      <description>&lt;p&gt;Huffman coding is a variation on prefix codes that optimize lossless data compression. In this deep dive, we (1) introduced how Huffman Codes work, (2) explored the theoretical limits of Huffman compression, (3) analyzed resilience to error, and (4) followed the evolution of research on using choice of Huffman tables to encode secret messages in MP3 files.&lt;/p&gt;
&lt;div id=&#34;Container&#34;
  style=&#34;padding-bottom:56.25%; position:relative; display:block; width: 100%&#34;&gt;
  &lt;iframe id=&#34;googlePdfIframe&#34;
  width=&#34;100%&#34; height=&#34;100%&#34;
  src=&#34;https://drive.google.com/file/d/1qZT_iiq8OeSeb5d5wkv4Jp9Ie-83-cm0/preview&#34;
  frameborder=&#34;0&#34; allowfullscreen=&#34;&#34;
  style=&#34;position:absolute; top:0; left: 0&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Survey of Data Structures for Large Scale Information Retrieval</title>
      <link>http://GatiAher.github.io/projects/survey-of-data-structures-for-large-scale-information-retrieval/</link>
      <pubDate>Sun, 09 May 2021 21:21:42 -0400</pubDate>
      
      <guid>http://GatiAher.github.io/projects/survey-of-data-structures-for-large-scale-information-retrieval/</guid>
      <description>&lt;p&gt;A survey of data structures used in large-scale information systems. Covers (i) how the inverted index data structure allows for constant time querying (ii) the need, problems, and clever design details of methods to compress big numbers (focusing on Elias-Fano and Partitioned Elias-Fano), and (iii) BitFunnel, an unusual probabilistic data structure used by the Bing search engine to bypass the curse of inverted index global updates.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5-minute video summary&lt;/strong&gt;:

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/UN6_yzZyczE&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>1D and 2D Fourier Transforms</title>
      <link>http://GatiAher.github.io/projects/1d-and-2d-fourier-transforms/</link>
      <pubDate>Wed, 03 Mar 2021 14:22:03 -0400</pubDate>
      
      <guid>http://GatiAher.github.io/projects/1d-and-2d-fourier-transforms/</guid>
      <description>&lt;p&gt;Concepts and math behind 1D and 2D discrete Fourier Transforms for signal and image analysis. Overview of mathematical steps, post-processing, assumptions, and reading of phase and magnitude plots.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>